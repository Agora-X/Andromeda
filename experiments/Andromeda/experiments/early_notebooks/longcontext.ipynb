{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","history_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyPkjLXA4xBbhYnb97bHZTbe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWo_uetFnSGP","executionInfo":{"status":"ok","timestamp":1683906576566,"user_tz":240,"elapsed":39262,"user":{"displayName":"Kye Gomez","userId":"16282839561288272368"}},"outputId":"b43604d2-ca91-42b0-8016-f3d0936928ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: colt5-attention in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from colt5-attention) (0.6.1)\n","Requirement already satisfied: local-attention>=1.8.6 in /usr/local/lib/python3.10/dist-packages (from colt5-attention) (1.8.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colt5-attention) (23.1)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from colt5-attention) (2.0.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->colt5-attention) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->colt5-attention) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->colt5-attention) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->colt5-attention) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->colt5-attention) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->colt5-attention) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->colt5-attention) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->colt5-attention) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->colt5-attention) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->colt5-attention) (1.3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","tokens: tensor([[[-0.1166,  2.7874, -1.0335,  ...,  0.4842, -0.2701,  1.9254],\n","         [ 0.3403, -0.5440,  1.1186,  ..., -0.2711,  1.1225,  0.3496],\n","         [ 0.5147, -3.2057, -0.0480,  ..., -0.3550,  0.6639,  0.2929],\n","         ...,\n","         [ 0.8364,  0.6330, -0.8668,  ...,  2.2426, -0.0989, -0.8650],\n","         [-0.3178, -1.0713,  0.8390,  ..., -1.8518,  0.4022, -0.1280],\n","         [-0.1367,  0.5613,  0.4291,  ..., -2.0379, -0.7547, -0.0296]],\n","\n","        [[ 0.3970, -0.2397, -0.4050,  ..., -1.8274, -0.8286, -0.4790],\n","         [ 1.6024,  2.0110, -0.5000,  ...,  0.4076,  0.6969, -0.3910],\n","         [ 2.3210, -0.7658, -1.0843,  ...,  0.0580,  1.0062,  0.1042],\n","         ...,\n","         [ 0.1934, -0.5202,  0.1969,  ...,  1.5385,  1.4037, -1.6028],\n","         [-1.9333,  0.2146,  0.2495,  ..., -0.1534,  0.3945,  1.4092],\n","         [ 0.6022,  0.6455,  0.6493,  ..., -0.8253, -1.0884, -0.6435]]])\n","mask: tensor([[True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True]])\n","feed forward: ConditionalRoutedFeedForward(\n","  (router): CoordinateDescentRouter()\n","  (light_ff): Sequential(\n","    (0): RMSNorm()\n","    (1): Linear(in_features=512, out_features=256, bias=True)\n","    (2): GELU(approximate='none')\n","    (3): Linear(in_features=256, out_features=512, bias=True)\n","  )\n","  (heavy_ff): Sequential(\n","    (0): RMSNorm()\n","    (1): Linear(in_features=512, out_features=2048, bias=True)\n","    (2): GELU(approximate='none')\n","    (3): Linear(in_features=2048, out_features=512, bias=True)\n","  )\n",")\n","Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n","attn out: tensor([[[-0.6692,  1.0667,  0.5301,  ...,  0.4843,  0.7589,  0.0893],\n","         [-0.6654,  1.0399,  0.5240,  ...,  0.5479,  0.7243,  0.1075],\n","         [-0.6511,  1.0580,  0.5400,  ...,  0.5415,  0.7363,  0.0848],\n","         ...,\n","         [-0.6156,  0.9069,  0.4678,  ...,  0.5375,  0.8062,  0.1784],\n","         [-0.6112,  0.9229,  0.4764,  ...,  0.5071,  0.7897,  0.1748],\n","         [-0.6458,  0.9458,  0.4822,  ...,  0.5191,  0.7759,  0.1980]],\n","\n","        [[-0.5842,  0.9299,  0.5531,  ...,  0.5411,  0.7859,  0.0567],\n","         [-0.5776,  0.9285,  0.5351,  ...,  0.5277,  0.7854,  0.0277],\n","         [-0.5469,  0.9171,  0.5435,  ...,  0.5429,  0.7945,  0.0519],\n","         ...,\n","         [-0.6380,  1.0065,  0.6321,  ...,  0.5250,  0.8305,  0.0844],\n","         [-0.6470,  1.0012,  0.6266,  ...,  0.5109,  0.8092,  0.0758],\n","         [-0.6541,  1.0156,  0.6361,  ...,  0.5077,  0.8319,  0.0904]]],\n","       grad_fn=<AddBackward0>)\n","block out: tensor([[[-0.2973,  2.3181, -0.8421,  ...,  1.3812,  1.3984,  2.7597],\n","         [ 0.1632, -0.7166,  1.1342,  ...,  0.5873,  2.7229,  1.2964],\n","         [ 0.4110, -3.3319,  0.1899,  ...,  0.4183,  2.3947,  1.3420],\n","         ...,\n","         [ 0.6759,  0.3325, -0.5291,  ...,  3.1939,  1.6591, -0.0349],\n","         [-0.3900, -1.2786,  0.9914,  ..., -0.9436,  2.1139,  0.7768],\n","         [-0.1983,  0.0110,  0.4590,  ..., -1.2616,  0.9646,  0.6547]],\n","\n","        [[ 0.5895, -0.6328, -0.1294,  ..., -1.0087,  0.7630,  0.5176],\n","         [ 1.4776,  1.6981, -0.1056,  ...,  1.2162,  2.2925,  0.7071],\n","         [ 2.0830, -0.8664, -0.9137,  ...,  0.8137,  2.5884,  1.0571],\n","         ...,\n","         [ 0.1858, -0.9142,  0.3548,  ...,  2.5995,  2.8922, -0.6656],\n","         [-1.9770,  0.1048,  0.4214,  ...,  0.9618,  2.1356,  2.1679],\n","         [ 0.2436,  0.2260,  0.8566,  ...,  0.3394,  0.4440,  0.2703]]],\n","       grad_fn=<AddBackward0>)\n"]}],"source":["!pip install colt5-attention\n","!pip install torch \n","\n","\n","import torch \n","from colt5_attention import (\n","    ConditionalRoutedFeedForward,\n","    ConditionalRoutedAttention,\n","    ConditionalRoutedTransformerBlock\n",")\n","\n","\n","#mock unout\n","tokens = torch.randn(2, 50000, 512)\n","print(f\"tokens: {tokens}\")\n","\n","mask = torch.ones(2, 50000).bool() #variable lenthed sequences\n","print(f\"mask: {mask}\")\n","\n","\n","ff = ConditionalRoutedFeedForward(\n","    dim= 512,\n","    light_ff_mult= 0.5,\n","    heavy_ff_mult = 4,\n","    num_heavy_tokens = 1024\n",")\n","\n","ff_out = ff(tokens, mask=mask)\n","print(f\"feed forward: {ff}\")\n","\n","\n","attn = ConditionalRoutedAttention(\n","    dim=512,\n","    light_dim_head=64,\n","    light_heads = 8,\n","    light_window_size=128,\n","    heavy_dim_head = 64,\n","    heavy_heads=8,\n","    num_heavy_tokens_q=1024,\n","    num_heavy_tokens_kv=1024,\n","    use_flash_attn = True\n",")\n","\n","attn_out = attn(tokens, mask=mask)\n","print(f\"attn out: {attn_out}\")\n","\n","block = ConditionalRoutedTransformerBlock(\n","    dim=512,\n","    light_dim_head=64,\n","    light_heads=8,\n","    light_window_size=128,\n","    heavy_dim_head=64,\n","    heavy_heads=8,\n","    light_ff_mult=0.5,\n","    heavy_ff_mult = 4,\n","    num_heavy_ff_tokens=1024,\n","    num_heavy_attn_tokens_q= 1024,\n","    num_heavy_attn_tokens_kv = 1024\n",")\n","\n","block_out = block(tokens, mask=mask)\n","\n","print(f\"block out: {block_out}\")"]},{"cell_type":"code","source":["#conditionally routed attention for cross atten tion\n","import torch \n","from colt5_attention import ConditionalRoutedCrossAttention\n","\n","#mock input lets say it is a transformer of 1024 attending to 1 million context memories\n","\n","\n","tokens = torch.randn(1, 1024, 512).cuda()\n","print(f\"tokens: {tokens}\")\n","\n","tokens_mask = torch.ones(1, 1024).bool().cuda()\n","print(f\"tokens mask: {tokens_mask}\")\n","\n","memories = torch.randn(1, 1_048_576, 512).cuda()\n","print(f\"memories: {memories}\")\n","\n","memories_mask = torch.ones(1, 1_048_576).bool().cuda()\n","print(f\"memories: {memories_mask}\")\n","\n","\n","#conditionally routed cross attention\n","cross_attn = ConditionalRoutedCrossAttention(\n","    dim=512,\n","    dim_head=64,\n","    heads=8,\n","    num_tokens_q=512,\n","    num_tokens_kv=1024,\n","    kv_routing_tokens=2,\n","    use_triton=True,\n","    route_block_size=131072\n",").cuda()\n","\n","cross_attn_out = cross_attn(\n","    tokens,\n","    context=memories,\n","    mask=tokens_mask,\n","    context_mask=memories_mask\n",")\n","\n","shape =  cross_attn_out.shape\n","print(f\"shape {shape}\" )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_F_KeTrco21q","executionInfo":{"status":"ok","timestamp":1683906886937,"user_tz":240,"elapsed":6450,"user":{"displayName":"Kye Gomez","userId":"16282839561288272368"}},"outputId":"d9d6d23c-3f6b-42b2-938a-b41d99ac1d77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tokens: tensor([[[ 1.0263,  0.0444,  0.4157,  ...,  1.9324,  0.2600,  0.0207],\n","         [-0.0459,  1.0451,  1.1374,  ...,  0.7586, -0.0329,  0.6849],\n","         [ 1.3423, -0.9727,  1.0685,  ...,  0.0900,  0.1832, -0.1667],\n","         ...,\n","         [ 0.2739,  1.6226,  0.5003,  ...,  0.3694,  0.3642,  0.2331],\n","         [ 0.7136, -0.2688, -0.0857,  ...,  0.2841,  0.3298,  0.0403],\n","         [ 1.6305,  0.0530,  0.3946,  ...,  0.5485, -0.5693,  0.0652]]],\n","       device='cuda:0')\n","tokens mask: tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n","memories: tensor([[[ 0.0280,  0.6959, -0.1431,  ..., -0.6348,  0.9171, -0.3882],\n","         [-0.0847,  0.1931, -0.6492,  ...,  0.6191, -0.3137,  1.0662],\n","         [-2.1065, -0.4429,  0.0470,  ..., -0.0771,  0.6260,  0.5998],\n","         ...,\n","         [-0.0182,  0.8396, -0.4933,  ...,  1.0157,  1.1854, -0.2614],\n","         [-0.3336,  1.1808,  0.5988,  ..., -1.2341,  0.4146, -2.2379],\n","         [ 1.8775, -0.3667,  0.7416,  ..., -1.0526,  0.5791, -0.0614]]],\n","       device='cuda:0')\n","memories: tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n","shape torch.Size([1, 1024, 512])\n"]}]},{"cell_type":"code","source":["!pip install x-transformers\n","\n","import torch \n","from x_transformers import TransformerWrapper, Decoder, AutoregressiveWrapper\n","\n","model = TransformerWrapper(\n","    num_tokens=20000,\n","    max_seq_len=5000,\n","    use_abs_pos_emb = False,\n","    attn_layers = Decoder(\n","        dim=512,\n","        depth=6,\n","        heads=8,\n","        alibi_pos_bias=True,\n","        alibi_num_heads=4,\n","        rotary_xpos=True,\n","        attn_flash = True,\n","        deepnorm=True,\n","        # dynamic_pos_bias=True,\n","        # dynamic_pos_bias_log_distance=False,\n","        shift_tokens=1,\n","        # rel_pos_bias=True\n","    )\n",")\n","\n","\n","model = AutoregressiveWrapper(\n","    model,\n","    mask_prob=0.15,\n",")\n","\n","x = torch.randint(0, 20000, (1, 5000))\n","print(f\"tokens: {x}\")\n","\n","# results = model(x)\n","\n","loss = model(x)\n","print(f\"loss: {loss}\")\n","\n","\n","result = loss.backward()\n","print(f\"Result: {result}\")\n","print(f\"results {result}\")\n","\n","#generate\n","# model.generate(seq_len=2000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"id":"5D2JYo1pud33","executionInfo":{"status":"error","timestamp":1683911349261,"user_tz":240,"elapsed":82933,"user":{"displayName":"Kye Gomez","userId":"16282839561288272368"}},"outputId":"1d25cd10-fca1-4b72-d788-400402c5f112"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: x-transformers in /usr/local/lib/python3.10/dist-packages (1.14.0)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.0+cu118)\n","Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n","tokens: tensor([[  958,   995, 18363,  ...,  2906, 13673,  3010]])\n","loss: 10.073033332824707\n","Result: None\n","results None\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d1e6ad22cdbe>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/x_transformers/autoregressive_wrapper.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mwas_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwas_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: AutoregressiveWrapper.generate() missing 1 required positional argument: 'start_tokens'"]}]},{"cell_type":"code","source":["import time\n","\n","import torch\n","from accelerate.utils import set_seed\n","from datasets import load_dataset\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","from transformers import get_scheduler, default_data_collator, get_linear_schedule_with_warmup\n","from torch.optim import AdamW\n","\n","from kosmos import Kosmos, KosmosTokenizer\n","from accelerate import Accelerator\n","\n","from rich.progress import Progress\n","from datasets import Image\n","from bitsandbytes.optim import AdamW8bit\n","\n","\n","def count_number_of_parameters(model, only_trainable: bool = True) -> int:\n","    if only_trainable:\n","        num_params: int = sum(p.numel()\n","                              for p in model.parameters() if p.requires_grad)\n","    else:\n","        num_params: int = sum(p.numel() for p in model.parameters() if p)\n","    return int(num_params)\n","\n","\n","\n","#change to enwiki8\n","def prep_sample(sample):\n","    question = sample[\"question\"]\n","    answer = sample[\"answer\"].split(\"|!+\")[1]\n","    explanation = sample[\"explanation\"]\n","    text = f\"Question: {question} Answer: {answer} Explanation: {explanation}\"\n","    image = sample[\"image\"]\n","    return {\n","        \"image\": image,\n","        \"target_text\": text\n","    }\n","\n","\n","def train(args):\n","    accelerator = Accelerator(\n","        mixed_precision=\"fp16\"\n","    )\n","\n","    # If passed along, set the training seed now.\n","    if args.seed is not None:\n","        set_seed(args.seed)\n","\n","    # change to andromeda\n","    model = Kosmos()\n","    model = model.to(accelerator.device)\n","\n","    optimizer = AdamW8bit(model.parameters(), lr=args.learning_rate,\n","                      weight_decay=args.weight_decay)\n","    lr_scheduler = get_linear_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=args.warmup_steps,\n","        num_training_steps=args.max_steps,\n","    )\n","\n","    #change to andromeda tokenizer\n","    tokenizer = KosmosTokenizer()\n","\n","    #change to enwiki\n","    dataset = load_dataset(\"bjoernp/vqax\", split=\"test\")\n","    #dataset = dataset.cast_column(\"URL\", Image)\n","    #map\n","    dataset = dataset.map(prep_sample, num_proc=8)\n","\n","    #change to enwiki\n","    remove_columns = ['id', 'img_id', 'question', 'answer',\n","                      'explanation', 'none', 'image', 'target_text']\n","\n","    #change batch_size\n","    dataset = dataset.map(tokenizer.tokenize, batched=True,\n","                          batch_size=128, remove_columns=remove_columns)\n","\n","    train_dataloader = DataLoader(\n","        dataset, collate_fn=default_data_collator, batch_size=args.batch_size, pin_memory=True\n","    )\n","\n","    model, train_dataloader, optimizer, lr_scheduler = accelerator.prepare(model, train_dataloader, optimizer,\n","                                                                           lr_scheduler)\n","    model.train()\n","    accelerator.register_for_checkpointing(lr_scheduler)\n","\n","    model.clip_model.requires_grad_(False)\n","    model.clip_model.encoder.layers[-1].requires_grad_(True)\n","\n","    accelerator.print(\n","        f\"Number of parameters: {count_number_of_parameters(model):,}\")\n","    accelerator.print(\n","        f\"Number of trainable parameters: {count_number_of_parameters(model, only_trainable=True):,}\")\n","\n","    # Log model and optimizer parameters to wandb\n","    accelerator.init_trackers(project_name=\"kosmos\")\n","\n","    train_loader = iter(train_dataloader)\n","    epoch_loss = 0\n","    total_loss = 0\n","    start_time = time.time()\n","\n","    with Progress() as progress:\n","        task = progress.add_task(\"[red]Training...\", total=args.max_steps)\n","        for step in range(0, args.max_steps):\n","            batch_start = time.time()\n","            batch = next(train_loader)\n","            outputs = model(**batch, self_attn_padding_mask=batch[\"attention_mask\"])\n","            # Shift so that tokens < n predict n\n","            outputs = torch.cat([outputs[:, :1], outputs[:, 67:]], dim=1).contiguous()\n","            # shift_logits = outputs[..., :-1, :].contiguous()\n","            # shift_labels = batch[\"labels\"][..., 1:].contiguous()\n","            # Flatten the tokens\n","            loss_fct = CrossEntropyLoss()\n","            one_hot_labels = torch.nn.functional.one_hot(batch[\"labels\"][:, 1:], num_classes=32002).float()\n","            loss = loss_fct(outputs[:,:-1], one_hot_labels)\n","\n","            epoch_loss += loss.detach().float()\n","\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            batch_end = time.time()\n","            logs = {\n","                \"loss\": loss.item(),\n","                \"perplexity\": torch.exp(loss).item(),\n","                \"lr\": lr_scheduler.get_last_lr()[0],\n","                \"examples\": args.batch_size * (step + 1),\n","                \"examples_per_second\": args.batch_size / (batch_end - batch_start),\n","            }\n","            if step % args.log_every == args.log_every - 1:\n","                accelerator.log(logs, step=step)\n","                progress.update(task, advance=1, description=f\"Step Loss: {loss.item():.5f} \"\n","                                                             f\"| Mean Loss: {(total_loss + epoch_loss) / step:.5f} \"\n","                                                             f\"| Mean PPL: {torch.exp((total_loss + epoch_loss) / step):.2f} \"\n","                                                             f\"| Examples: {args.batch_size * (step + 1)} \"\n","                                                             f\"| Examples/s: {args.batch_size / (batch_end - batch_start):.2f} \"\n","                                                             f\"| Elapsed: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))}\")\n","\n","            if step % args.save_every == args.save_every - 1:\n","                train_epoch_loss = epoch_loss / args.save_every\n","                total_loss += epoch_loss\n","                epoch_loss = 0\n","\n","                accelerator.log({\n","                    \"train_ppl\": torch.exp(train_epoch_loss),\n","                    \"train_epoch_loss\": train_epoch_loss,\n","                }, step=step)\n","\n","                progress.print(f\"Saving checkpoint at step {step}...\")\n","                accelerator.save_state(\n","                    f\"{args.checkpoint_dir}/checkpoint_at_step_{step}/\")\n","\n"],"metadata":{"id":"-XN_7QeP7OnJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/kyegomez/Optimus-Prime.git\n","%cd Optimus-Prime\n","%cd examples\n","%cd enwiki8_simple\n","\n","from torch.serialization import load\n","import torch \n","from x_transformers import TransformerWrapper, Decoder, AutoregressiveWrapper\n","\n","#training\n","import random\n","import tqdm\n","import gzip\n","import numpy as np\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","# constants\n","\n","NUM_BATCHES = int(1e5)\n","BATCH_SIZE = 4\n","GRADIENT_ACCUMULATE_EVERY = 4\n","LEARNING_RATE = 1e-4\n","VALIDATE_EVERY  = 100\n","GENERATE_EVERY  = 500\n","GENERATE_LENGTH = 1024\n","SEQ_LEN = 1024\n","\n","# helpers\n","\n","def cycle(loader):\n","    while True:\n","        for data in loader:\n","            yield data\n","\n","def decode_token(token):\n","    return str(chr(max(32, token)))\n","\n","def decode_tokens(tokens):\n","    return ''.join(list(map(decode_token, tokens)))\n","\n","model = TransformerWrapper(\n","    num_tokens=20000,\n","    max_seq_len=5000,\n","    use_abs_pos_emb = False,\n","    attn_layers = Decoder(\n","        dim=512,\n","        depth=6,\n","        heads=8,\n","        alibi_pos_bias=True,\n","        alibi_num_heads=4,\n","        rotary_xpos=True,\n","        attn_flash = True,\n","        deepnorm=True,\n","        # dynamic_pos_bias=True,\n","        # dynamic_pos_bias_log_distance=False,\n","        shift_tokens=1,\n","        # rel_pos_bias=True\n","    )\n",")\n","\n","\n","model = AutoregressiveWrapper(model)\n","model.cuda()\n","\n","with gzip.open('./data/enwik8.gz') as file:\n","  data = np.frombuffer(file.read(int(95e6)), dtype=np.uint8).copy()\n","  train_x, valid_x = np.split(data, [int(90e6)])\n","  data_train, data_val = torch.from_numpy(train_x), torch.from_numpy(valid_x)\n","\n","class TextSamplerDataset(Dataset):\n","    def __init__(self, data, seq_len):\n","        super().__init__()\n","        self.data = data\n","        self.seq_len = seq_len\n","\n","    def __getitem__(self, index):\n","        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n","        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n","        return full_seq.cuda()\n","\n","    def __len__(self):\n","        return self.data.size(0) // self.seq_len\n","\n","train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n","val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n","train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE, drop_last = True))\n","val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE, drop_last = True))\n","\n","# optimizer\n","\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# training\n","\n","for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n","    model.train()\n","\n","    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n","        loss = model(next(train_loader))\n","        (loss / GRADIENT_ACCUMULATE_EVERY).backward()\n","\n","    print(f'training loss: {loss.item()}')\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    optim.step()\n","    optim.zero_grad()\n","\n","    if i % VALIDATE_EVERY == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            loss = model(next(val_loader))\n","            print(f'validation loss: {loss.item()}')\n","\n","    if i % GENERATE_EVERY == 0:\n","        model.eval()\n","        inp = random.choice(val_dataset)[:-1]\n","        prime = decode_tokens(inp)\n","        print(f'%s \\n\\n %s', (prime, '*' * 100))\n","\n","        sample = model.generate(inp, GENERATE_LENGTH)\n","        output_str = decode_tokens(sample)\n","        print(output_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtQoE4IB-rre","executionInfo":{"status":"ok","timestamp":1683913796818,"user_tz":240,"elapsed":1677,"user":{"displayName":"Kye Gomez","userId":"16282839561288272368"}},"outputId":"ccd7de86-a2bb-4f22-cbb5-1ebcbb436633"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Optimus-Prime'...\n","remote: Enumerating objects: 1614, done.\u001b[K\n","remote: Counting objects: 100% (1614/1614), done.\u001b[K\n","remote: Compressing objects: 100% (531/531), done.\u001b[K\n","remote: Total 1614 (delta 1113), reused 1529 (delta 1073), pack-reused 0\u001b[K\n","Receiving objects: 100% (1614/1614), 37.48 MiB | 47.50 MiB/s, done.\n","Resolving deltas: 100% (1113/1113), done.\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple\n","  File \"/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/trainandromeda.py\", line 1\n","    !git clone https://github.com/kyegomez/Optimus-Prime.git\n","    ^\n","SyntaxError: invalid syntax\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/kyegomez/Optimus-Prime.git\n","%cd Optimus-Prime\n","%cd examples\n","%cd enwik8_simple\n","!python3 trainandromeda.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vE38nIxnEgqi","executionInfo":{"status":"ok","timestamp":1683913660063,"user_tz":240,"elapsed":2192,"user":{"displayName":"Kye Gomez","userId":"16282839561288272368"}},"outputId":"1930b33b-9170-4b9e-9c92-4c3c27109095"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Optimus-Prime'...\n","remote: Enumerating objects: 1614, done.\u001b[K\n","remote: Counting objects: 100% (453/453), done.\u001b[K\n","remote: Compressing objects: 100% (191/191), done.\u001b[K\n","remote: Total 1614 (delta 309), reused 367 (delta 260), pack-reused 1161\u001b[K\n","Receiving objects: 100% (1614/1614), 37.51 MiB | 45.67 MiB/s, done.\n","Resolving deltas: 100% (1100/1100), done.\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple\n","  File \"/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/Optimus-Prime/examples/enwik8_simple/Optimus-Prime/examples/enwik8_simple/trainandromeda.py\", line 1\n","    !git clone https://github.com/kyegomez/Optimus-Prime.git\n","    ^\n","SyntaxError: invalid syntax\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/kyegomez/Optimus-Prime.git\n","%cd Optimus-Prime\n","!pip install --upgrade torch\n","# !pip install -r requirements.txt\n","!pip install einops\n","# !pip install --upgrade torch\n","\n","# %cd Optimus-Prime\n","# # %cd examples\n","# # !ls\n","# !python3 trainandromeda.py \n","# #%cd enwik8_simple\n","# # !python trainandromeda.py\n","\n","\n","from torch.serialization import load\n","import torch \n","from optimus_prime import TransformerWrapper, Decoder, AutoregressiveWrapper\n","\n","#training\n","import random\n","import tqdm\n","import gzip\n","import numpy as np\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","# from torch.utils.tensorboard import SummaryWriter\n","# from torchmetrics import MetricCollection, Accuracy\n","\n","\n","# constants\n","\n","NUM_BATCHES = int(1e5)\n","BATCH_SIZE = 4\n","GRADIENT_ACCUMULATE_EVERY = 4\n","LEARNING_RATE = 1e-4\n","VALIDATE_EVERY  = 100\n","GENERATE_EVERY  = 500\n","GENERATE_LENGTH = 1024\n","SEQ_LEN = 1024\n","SAVE_EVERY=500\n","\n","\n","# helpers\n","\n","def cycle(loader):\n","    while True:\n","        for data in loader:\n","            yield data\n","\n","def decode_token(token):\n","    return str(chr(max(32, token)))\n","\n","def decode_tokens(tokens):\n","    return ''.join(list(map(decode_token, tokens)))\n","\n","model = TransformerWrapper(\n","    num_tokens=20000,\n","    max_seq_len=5000,\n","    use_abs_pos_emb = False,\n","    attn_layers = Decoder(\n","        dim=512,\n","        depth=6,\n","        heads=8,\n","        alibi_pos_bias=True,\n","        alibi_num_heads=4,\n","        rotary_xpos=True,\n","        attn_flash = True,\n","        deepnorm=True,\n","        # dynamic_pos_bias=True,\n","        # dynamic_pos_bias_log_distance=False,\n","        shift_tokens=1,\n","        # rel_pos_bias=True\n","    )\n",")\n","\n","\n","model = AutoregressiveWrapper(model)\n","model.cuda()\n","\n","with gzip.open('./enwik8.gz') as file:\n","  data = np.frombuffer(file.read(int(95e6)), dtype=np.uint8).copy()\n","  train_x, valid_x = np.split(data, [int(90e6)])\n","  data_train, data_val = torch.from_numpy(train_x), torch.from_numpy(valid_x) #.cuda()??\n","\n","class TextSamplerDataset(Dataset):\n","    def __init__(self, data, seq_len):\n","        super().__init__()\n","        self.data = data\n","        self.seq_len = seq_len\n","\n","    def __getitem__(self, index):\n","        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n","        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n","        return full_seq.cuda()\n","\n","    def __len__(self):\n","        return self.data.size(0) // self.seq_len\n","\n","train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n","val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n","train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE, drop_last = True))\n","val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE, drop_last = True))\n","\n","# optimizer\n","\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# training\n","\n","# #init tensorboard \n","# writer = SummaryWriter(log_dir=\"./log\")\n","\n","# #define metrics\n","# metrics = MetricCollection({'accuracy': Accuracy(num_classes=num_classes, task='classification')})\n","device=\"cuda\"\n","for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n","    model.train()\n","\n","    for _ in range(GRADIENT_ACCUMULATE_EVERY):\n","        loss = model(next(train_loader))#.to(device)\n","        (loss / GRADIENT_ACCUMULATE_EVERY).backward()#.to(device)#.cuda()\n","\n","    print(f'training loss: {loss.item()}')\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    optim.step()\n","    optim.zero_grad()\n","\n","\n","    if i % VALIDATE_EVERY == 0:\n","            model.eval()\n","            with torch.no_grad():\n","                loss = model(next(val_loader))\n","                print(f'validation loss: {loss.item()}')\n","\n","                # # Calculate validation metrics\n","                # val_metrics = MetricCollection({'val_accuracy': Accuracy()})\n","                # val_metrics(loss, model(next(val_loader)).argmax(dim=-1))\n","\n","                # # Add validation metrics to the SummaryWriter\n","                # writer.add_scalar('Validation/Accuracy', val_metrics['val_accuracy'].compute(), global_step=i)\n","\n","    if i % GENERATE_EVERY == 0:\n","        model.eval()\n","        inp = random.choice(val_dataset)[:-1]\n","        prime = decode_tokens(inp)\n","        print(f'%s \\n\\n %s', (prime, '*' * 100))\n","\n","        sample = model.generate(inp, GENERATE_LENGTH)\n","        output_str = decode_tokens(sample)\n","        print(output_str)\n","\n","    # Save the model every save_every iterations\n","    if i % SAVE_EVERY == 0:\n","        # Specify the directory and filename to save the model\n","        save_dir = './saved_models/'\n","        save_filename = 'model_checkpoint.pt'\n","        from google.colab import files\n","        files.download(save_filename)\n","\n","        # Create the save directory if it doesn't exist\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","        # Save the model checkpoint\n","        torch.save(model.state_dict(), os.path.join(save_dir, save_filename))\n","        print(f\"Model saved at iteration {i}\")\n","\n","#     # Add training metrics to the SummaryWriter\n","#     writer.add_scalar('Training/Accuracy', metrics['accuracy'].compute(), global_step=i)\n","\n","#     # Close the SummaryWriter\n","# writer.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fbfP8gARFEiH","executionInfo":{"status":"error","timestamp":1683954157696,"user_tz":240,"elapsed":11759,"user":{"displayName":"Kye Gomez","userId":"16282839561288272368"}},"outputId":"76818dff-d185-42bc-f22b-53d1f40bbcbe"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Optimus-Prime'...\n","remote: Enumerating objects: 1674, done.\u001b[K\n","remote: Counting objects: 100% (513/513), done.\u001b[K\n","remote: Compressing objects: 100% (231/231), done.\u001b[K\n","remote: Total 1674 (delta 341), reused 412 (delta 277), pack-reused 1161\u001b[K\n","Receiving objects: 100% (1674/1674), 37.52 MiB | 17.27 MiB/s, done.\n","Resolving deltas: 100% (1132/1132), done.\n","/content/Optimus-Prime/Optimus-Prime/Optimus-Prime\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"]},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-440f2293afd8>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0moptimus_prime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoregressiveWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Optimus-Prime/Optimus-Prime/Optimus-Prime/optimus_prime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mallow_ops_in_compiled_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimus_prime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossAttender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mViTransformerWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinuousTransformerWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moptimus_prime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoregressive_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoregressiveWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: attempted relative import beyond top-level package","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"qZCg1uRhQdtS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","# with multiquery + flash + alibi + xpos + deepnorm\n","```\n","\n","# New Section"],"metadata":{"id":"RnK98pKZcU0q"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"K-KQhI0nxbcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#concurrency\n","!git clone https://github.com/kyegomez/Optimus-Prime.git\n","!pip install einops\n","!pip install torchmetrics\n","!pip install tensorboard\n","\n","!pip install -r requirements.txt\n","%cd Optimus-Prime\n","\n","import threading\n","\n","def run_tensorboard():\n","    !tensorboard --logdir=./logs --port=6006\n","\n","def run_training():\n","    !python3 trainandromeda.py\n","\n","# Start TensorBoard in a separate thread\n","tensorboard_thread = threading.Thread(target=run_tensorboard)\n","tensorboard_thread.start()\n","\n","# Run the training script\n","run_training()\n","\n","# Wait for the TensorBoard thread to finish\n","tensorboard_thread.join()"],"metadata":{"id":"KIkSr-2rOIMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/kyegomez/Optimus-Prime.git\n","%cd Optimus-Prime\n","!pip install --upgrade torch\n","# !pip install -r requirements.txt\n","!pip install einops\n","# !pip install --upgrade torch\n","\n","# %cd Optimus-Prime\n","# # %cd examples\n","# # !ls\n","# !python3 trainandromeda.py \n","# #%cd enwik8_simple\n","# # !python trainandromeda.py\n","\n","\n","from torch.serialization import load\n","import torch \n","from x_transformers import TransformerWrapper, Decoder, AutoregressiveWrapper\n","\n","#training\n","import random\n","import tqdm\n","import gzip\n","import numpy as np\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","# from torch.utils.tensorboard import SummaryWriter\n","# from torchmetrics import MetricCollection, Accuracy\n","\n","\n","# constants\n","\n","NUM_BATCHES = int(1e5)\n","BATCH_SIZE = 4\n","GRADIENT_ACCUMULATE_EVERY = 4\n","LEARNING_RATE = 1e-4\n","VALIDATE_EVERY  = 100\n","GENERATE_EVERY  = 500\n","GENERATE_LENGTH = 1024\n","SEQ_LEN = 1024\n","SAVE_EVERY=500\n","\n","\n","# helpers\n","\n","def cycle(loader):\n","    while True:\n","        for data in loader:\n","            yield data\n","\n","def decode_token(token):\n","    return str(chr(max(32, token)))\n","\n","def decode_tokens(tokens):\n","    return ''.join(list(map(decode_token, tokens)))\n","\n","model = TransformerWrapper(\n","    num_tokens=20000,\n","    max_seq_len=5000,\n","    use_abs_pos_emb = False,\n","    attn_layers = Decoder(\n","        dim=512,\n","        depth=6,\n","        heads=8,\n","        alibi_pos_bias=True,\n","        alibi_num_heads=4,\n","        rotary_xpos=True,\n","        attn_flash = True,\n","        deepnorm=True,\n","        # dynamic_pos_bias=True,\n","        # dynamic_pos_bias_log_distance=False,\n","        shift_tokens=1,\n","        attn_one_kv_head = True,\n","        # rel_pos_bias=True\n","    )\n",")\n","\n","\n","model = AutoregressiveWrapper(model)\n","model.cuda()\n","\n","with gzip.open('./enwik8.gz') as file:\n","  data = np.frombuffer(file.read(int(95e6)), dtype=np.uint8).copy()\n","  train_x, valid_x = np.split(data, [int(90e6)])\n","  data_train, data_val = torch.from_numpy(train_x), torch.from_numpy(valid_x) #.cuda()??\n","\n","class TextSamplerDataset(Dataset):\n","    def __init__(self, data, seq_len):\n","        super().__init__()\n","        self.data = data\n","        self.seq_len = seq_len\n","\n","    def __getitem__(self, index):\n","        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n","        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n","        return full_seq.cuda()\n","\n","    def __len__(self):\n","        return self.data.size(0) // self.seq_len\n","\n","train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n","val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n","train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE, drop_last = True))\n","val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE, drop_last = True))\n","\n","# optimizer\n","\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# training\n","\n","# #init tensorboard \n","# writer = SummaryWriter(log_dir=\"./log\")\n","\n","# #define metrics\n","# metrics = MetricCollection({'accuracy': Accuracy(num_classes=num_classes, task='classification')})\n","device=\"cuda\"\n","for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n","    model.train()\n","\n","    for _ in range(GRADIENT_ACCUMULATE_EVERY):\n","        loss = model(next(train_loader))#.to(device)\n","        (loss / GRADIENT_ACCUMULATE_EVERY).backward()#.to(device)#.cuda()\n","\n","    print(f'training loss: {loss.item()}')\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    optim.step()\n","    optim.zero_grad()\n","\n","\n","    if i % VALIDATE_EVERY == 0:\n","            model.eval()\n","            with torch.no_grad():\n","                loss = model(next(val_loader))\n","                print(f'validation loss: {loss.item()}')\n","\n","                # # Calculate validation metrics\n","                # val_metrics = MetricCollection({'val_accuracy': Accuracy()})\n","                # val_metrics(loss, model(next(val_loader)).argmax(dim=-1))\n","\n","                # # Add validation metrics to the SummaryWriter\n","                # writer.add_scalar('Validation/Accuracy', val_metrics['val_accuracy'].compute(), global_step=i)\n","\n","    if i % GENERATE_EVERY == 0:\n","        model.eval()\n","        inp = random.choice(val_dataset)[:-1]\n","        prime = decode_tokens(inp)\n","        print(f'%s \\n\\n %s', (prime, '*' * 100))\n","\n","        sample = model.generate(inp, GENERATE_LENGTH)\n","        output_str = decode_tokens(sample)\n","        print(output_str)\n","\n","    # Save the model every save_every iterations\n","    if i % SAVE_EVERY == 0:\n","        # Specify the directory and filename to save the model\n","        save_dir = './saved_models/'\n","        save_filename = 'model_checkpoint.pt'\n","\n","        # Create the save directory if it doesn't exist\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","        # Save the model checkpoint\n","        torch.save(model.state_dict(), os.path.join(save_dir, save_filename))\n","        print(f\"Model saved at iteration {i}\")\n","\n","#     # Add training metrics to the SummaryWriter\n","#     writer.add_scalar('Training/Accuracy', metrics['accuracy'].compute(), global_step=i)\n","\n","#     # Close the SummaryWriter\n","# writer.close()"],"metadata":{"id":"q_QnMOxIiv4D"},"execution_count":null,"outputs":[]}]}